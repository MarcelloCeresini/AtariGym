{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/applications/efficientnet.py:288: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 12 input channels.\n",
      "  input_shape = imagenet_utils.obtain_input_shape(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4015264\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import sample\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU')[0])\n",
    "\n",
    "experience_buffer = collections.deque([])\n",
    "REAPLAY_MEMORY_SIZE = 10000 # should be 1000000\n",
    "\n",
    "env = gym.make(\"ALE/Breakout-v5\")\n",
    "\n",
    "N_ACTIONS = env.action_space.n\n",
    "OBS_RANGE = int(env.observation_space.high_repr) - int(env.observation_space.low_repr)\n",
    "OBS_SHAPE = env.observation_space.shape\n",
    "# SKIP_FRAMES = [2, 3, 4] # possible addition --> skip randomly 2/3/4 frames instead of always 4\n",
    "N_INPUT_FRAMES = 4\n",
    "\n",
    "REPLAY_START_SIZE = 500 # should be 50000\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "input_shape = [*OBS_SHAPE]\n",
    "input_shape[-1] *= N_INPUT_FRAMES\n",
    "\n",
    "obs = np.zeros(input_shape)\n",
    "\n",
    "model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=input_shape,\n",
    "    classes=N_ACTIONS,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "total_params = sum([np.prod(w.get_shape().as_list()) for w in model.trainable_weights])\n",
    "print(total_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_observation(obs):\n",
    "    return obs / OBS_RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(action):\n",
    "    i = 0\n",
    "    k_reward = 0\n",
    "    done = 0\n",
    "    while i < N_INPUT_FRAMES and not done:\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        obs[:, :, i:i+3] = observation\n",
    "        i += 1\n",
    "        k_reward += reward\n",
    "\n",
    "    p_obs = preprocess_observation(obs)\n",
    "    return p_obs, k_reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"efficientnetb0\" is incompatible with the layer: expected shape=(None, 210, 160, 12), found shape=(210, 160, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/marcello/github/AtariGym/main.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/AtariGym/main.ipynb#ch0000002?line=18'>19</a>\u001b[0m       k_reward \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/AtariGym/main.ipynb#ch0000002?line=20'>21</a>\u001b[0m p_obs \u001b[39m=\u001b[39m preprocess_observation(obs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marcello/github/AtariGym/main.ipynb#ch0000002?line=22'>23</a>\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(model(p_obs)) \u001b[39m# CUDDN dio merda\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/AtariGym/main.ipynb#ch0000002?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(action)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/AtariGym/main.ipynb#ch0000002?line=25'>26</a>\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/github/AtariGym/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/github/AtariGym/env/lib/python3.8/site-packages/keras/engine/input_spec.py:264\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/engine/input_spec.py?line=261'>262</a>\u001b[0m \u001b[39mif\u001b[39;00m spec_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/engine/input_spec.py?line=262'>263</a>\u001b[0m   \u001b[39mif\u001b[39;00m spec_dim \u001b[39m!=\u001b[39m dim:\n\u001b[0;32m--> <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/engine/input_spec.py?line=263'>264</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/engine/input_spec.py?line=264'>265</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mincompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/engine/input_spec.py?line=265'>266</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected shape=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/marcello/github/AtariGym/env/lib/python3.8/site-packages/keras/engine/input_spec.py?line=266'>267</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound shape=\u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"efficientnetb0\" is incompatible with the layer: expected shape=(None, 210, 160, 12), found shape=(210, 160, 12)"
     ]
    }
   ],
   "source": [
    "counter_replay_start = 0\n",
    "\n",
    "for _ in range(int(1e6)):                           # n° of episodes\n",
    "\n",
    "      observation, info = env.reset(seed=42, return_info=True)\n",
    "      action = env.action_space.sample() # how do you solve the first frame? which action do you choose? (since the obs are 4 frames concat)\n",
    "\n",
    "      for _ in range(int(1e3)):                     # n° of frames per episode\n",
    "\n",
    "            i = 0\n",
    "            k_reward = 0\n",
    "            done = 0\n",
    "            # sample_k_frames = sample(SKIP_FRAMES, 1)[0]\n",
    "            \n",
    "            while i < N_INPUT_FRAMES and not done:\n",
    "\n",
    "                  observation, reward, done, info = env.step(action)\n",
    "                  obs[:, :, i:i+3] = observation\n",
    "                  i += 1\n",
    "                  k_reward += reward\n",
    "\n",
    "            p_obs = preprocess_observation(obs)\n",
    "\n",
    "            if counter_replay_start > REPLAY_START_SIZE:\n",
    "                  sample(experience_buffer, BATCH_SIZE)\n",
    "\n",
    "            else:\n",
    "                  counter_replay_start += 1\n",
    "\n",
    "            if counter_replay_start < REPLAY_START_SIZE:\n",
    "                  # random sampling the first \"REPLAY_START_SIZE\" steps\n",
    "                  action = env.action_space.sample()\n",
    "                  counter_replay_start += 1\n",
    "                  next_p_obs, reward, is_end_state = simulate(action) \n",
    "                  experience_buffer.append((p_obs, action, reward, next_p_obs, is_end_state))\n",
    "            else:\n",
    "                  # policy\n",
    "                  if np.random.uniform() < eps:\n",
    "                        action = env.action_space.sample()\n",
    "                  else:\n",
    "                        action = max(model(p_obs))\n",
    "            print(action)\n",
    "\n",
    "            observation, reward, done, info = env.step(0)\n",
    "\n",
    "            if done:\n",
    "                observation, info = env.reset(return_info=True)\n",
    "            # break\n",
    "            break\n",
    "      break\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
